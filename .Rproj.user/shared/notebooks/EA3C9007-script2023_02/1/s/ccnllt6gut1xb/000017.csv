"0","#library(doc2vec)"
"0",""
"0",""
"0","# On constitue le corpus"
"0",""
"0","corp<-corpus(dn$text, docvars =dn)"
"0","toks <- tokens(corp, remove_punct = TRUE, padding=TRUE )%>%"
"0","  tokens_tolower() %>% "
"0"," tokens_select(pattern = stopwords('french'), selection = 'remove')"
"0",""
"0","# On calcule les collocations"
"0",""
"0","#collocation"
"0","tstat_col_caps <- "
"0","  tokens_select(toks, case_insensitive = TRUE,"
"0","                                padding = TRUE) %>% "
"0","           textstat_collocations(min_count = 4, size=2:5) %>%"
"0","  filter(lambda>3 & z>4)"
"0",""
"0","#integration"
"0","toks_comp <- tokens_compound(toks, pattern = tstat_col_caps) "
"0",""
"0",""
"0","#statistiques des mots"
"0",""
"0","dfm <-  dfm(toks_comp)"
"0",""
"0","tstat_freq <- as.data.frame(textstat_frequency(dfm))"
"0",""
"0","N<-as.numeric(nrow(tstat_freq)) #nombre de doc"
"0","M=sum(tstat_freq$frequency) #nombre de mot"
"0",""
"0","tstat_freq2<-tstat_freq %>% "
"0","  mutate(idf=log(N/docfreq),"
"0","         tfidf=(frequency/M)*idf) %>%"
"0","  rename(words=feature)"
"0",""
"0",""
"0",""
