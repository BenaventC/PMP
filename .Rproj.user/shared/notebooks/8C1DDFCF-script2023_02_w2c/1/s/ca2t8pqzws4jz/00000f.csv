"0",""
"0",""
"0","#on matche Ã  key et on content le nombre de token par document"
"0","doc <- tokens %>%"
"0","  group_by(doc_id) %>%"
"0","  summarise(n_tok_doc=n()) %>%"
"0","  cbind(dn[,1])"
"0",""
"0","#pour l'IDF"
"0","words_total<-as.numeric(nrow(tokens)) #nombre total de tokens dans le corpus"
"0","doc_total=as.numeric(nrow(dn))"
"0",""
"0","#on calcule la frequence des lemmas/upos"
"0","tokens_lemma<-tokens %>% "
"0","  left_join(doc)%>%"
"0","  group_by(Key,lemma)%>%"
"0","  summarise(n=n(), Key=first(Key),upos=first(upos))"
"2","Joining with `by = join_by(doc_id)`"
"2","`summarise()` has grouped output by 'Key'. You can override using the `.groups` argument."
"0","tokens_lemma2<-tokens_lemma%>% "
"0","    group_by(lemma)%>%"
"0","  summarise(n_doc=n(), "
"0","            upos=first(upos),"
"0","            frequency=sum(n),"
"0","            tf= frequency/words_total,"
"0","            idf=log(doc_total/n_doc),"
"0","            tfidf=tf*idf)"
"0",""
"0","ggplot(tokens_lemma2, aes(x=tfidf))+geom_density(kernel = ""triangular"")+scale_x_log10()+scale_y_log10()"
